<!DOCTYPE html>
<html>
	<head>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1.0" />
		<title>Bibliography</title>
		<meta
			name="description"
			content="This site hosts the bibliography for my current research project. It provides an organized list of all references used."
		/>
		<meta name="author" content="Juan Pablo Gutiérrez Restrepo" />
		<link rel="stylesheet" href="https://stackedit.io/style.css" />
		<link rel="icon" href="misc/favicon.ico" type="image/x-icon" />
	</head>

	<body class="stackedit">
		<div class="stackedit__left">
			<div class="stackedit__toc">
				<ul>
					<li>
						<a href="#bibliography">Bibliography</a>
						<ul>
							<li><a href="#western-bias-in-ai">Western Bias in AI</a></li>
							<li>
								<a href="#cross-cultural-studies-in-psychology-and-ai"
									>Cross-Cultural Studies in Psychology and AI</a
								>
							</li>
							<li><a href="#ai-regulation">AI Regulation</a></li>
							<li>
								<a href="#human-in-the-loop-and-ai-fairness"
									>Human-in-the-loop and AI Fairness</a
								>
							</li>
							<li><a href="#human-ai-collaboration">Human-AI Collaboration</a></li>
							<li>
								<a href="#algorithmic-fairness-and-bias"
									>Algorithmic Fairness and Bias</a
								>
							</li>
							<li>
								<a href="#additional-readings">Additional Readings</a>
								<ul>
									<li></li>
								</ul>
							</li>
						</ul>
					</li>
				</ul>
			</div>
		</div>
		<div class="stackedit__right">
			<div class="stackedit__html">
				<h1 id="bibliography">Bibliography</h1>
				<h2 id="western-bias-in-ai">Western Bias in AI</h2>
				<ul>
					<li>
						<strong>Zhu, L., Mou, W., Lai, Y. et al.</strong> (2024). “Language and
						cultural bias in AI: comparing the performance of large language models
						developed in different countries on Traditional Chinese Medicine highlights
						the need for localized models,”
						<em><strong>Journal of Translational Medicine</strong></em
						>, 22, 319.
						<a href="https://doi.org/10.1186/s12967-024-03598-6"
							>DOI: 10.1186/s12967-024-03598-6</a
						>.
					</li>
					<li>
						<strong>Malik et al.</strong> (2022). “Socially Aware Bias Measurements for
						Hindi Language Representations,” <em><strong>NAACL 2022</strong></em
						>.
					</li>
					<li>
						<strong>Bhatt et al.</strong> (2022). “Re-contextualizing Fairness in NLP:
						The Case of India,” <em><strong>AACL-IJCNLP 2022</strong></em
						>.
					</li>
					<li>
						<strong>Peters, Uwe, &amp; Carman, Mary.</strong> “Cultural Bias in
						Explainable AI Research: A Systematic Analysis.”
					</li>
				</ul>
				<h2 id="cross-cultural-studies-in-psychology-and-ai">
					Cross-Cultural Studies in Psychology and AI
				</h2>
				<ul>
					<li>
						<strong>Masuda, T., &amp; Nisbett, R. E.</strong> (2001). “Attending
						holistically versus analytically: comparing the context sensitivity of
						Japanese and Americans,”
						<em><strong>Journal of Personality and Social Psychology</strong></em
						>, 81(5), 922-934.
					</li>
					<li>
						<strong>Yiend J, André J, Smith L, Chen LH, Toulopoulou T, et al.</strong>
						(2019). “Biased cognition in East Asian and Western cultures,”
						<em><strong>PLOS ONE</strong></em
						>, 14(10): e0223358.
						<a href="https://doi.org/10.1371/journal.pone.0223358"
							>DOI: 10.1371/journal.pone.0223358</a
						>.
					</li>
				</ul>
				<h2 id="ai-regulation">AI Regulation</h2>
				<ul>
					<li>
						<strong
							>Japan’s Approach to AI Regulation and Its Impact on 2023 G7
							Presidency</strong
						>. (2023).
						<a
							href="https://www.csis.org/analysis/japans-approach-ai-regulation-and-its-impact-2023-g7-presidency"
							>CSIS</a
						>.
					</li>
				</ul>
				<h2 id="human-in-the-loop-and-ai-fairness">Human-in-the-loop and AI Fairness</h2>
				<ul>
					<li>
						<strong
							>Nakao, Yuri, Stumpf, Simone, Ahmed, Subeida, Naseer, Aisha, &amp;
							Strappelli, Lorenzo.</strong
						>
						(2022). “Toward Involving End-users in Interactive Human-in-the-loop AI
						Fairness,”
						<em
							><strong
								>ACM Trans. Interact. Intell. Syst. 12(3), Article 18</strong
							></em
						>. <a href="https://doi.org/10.1145/3514258">DOI: 10.1145/3514258</a>.
					</li>
				</ul>
				<h2 id="human-ai-collaboration">Human-AI Collaboration</h2>
				<ul>
					<li>
						<strong
							>De-Arteaga, M., Gao, R., Saar-Tsechansky, M., Han, L., Lee, MK, Sun,
							W., &amp; Lease, M.</strong
						>
						(2022). “Learning Complementary Policies for Human-AI Teams,”
						<em><strong>CIST’22</strong></em
						>. Best Student Paper Award.
					</li>
					<li>
						<strong>De-Arteaga, M., Schoeffer, J., &amp; Kuehl, N.</strong> (2024).
						“Explanations, Fairness, and Appropriate Reliance in Human-AI
						Decision-Making,”
						<em
							><strong
								>Proceedings of ACM CHI Conference on Human Factors in Computing
								Systems (CHI) 2024</strong
							></em
						>. Honorable Mention Award (top 5%).
					</li>
				</ul>
				<h2 id="algorithmic-fairness-and-bias">Algorithmic Fairness and Bias</h2>
				<ul>
					<li>
						<strong
							>De-Arteaga, M., Neumann, T., Lee, S., Fazelpour, S., &amp; Lease,
							M.</strong
						>
						“Diverse, but Divisive: LLMs Can Exaggerate Gender Differences in Opinion
						Related to Harms of Misinformation.”
					</li>
					<li>
						<strong
							>De-Arteaga, M., Jeanselme, V., Dubrawski, A., &amp; Chouldechova,
							A.</strong
						>
						(2021). “Leveraging Expert Consistency to Improve Algorithmic Decision
						Support,” <em><strong>WITS’21</strong></em
						>. Best Paper Runner-Up Award.
					</li>
					<li>
						<strong
							>Cheng, Myra, Mackey, Lester, Kalai, Adam, &amp; De-Arteaga, M.</strong
						>
						(2023). “Social Norm Bias: Residual Harms of Fairness-Aware Algorithms,”
						<em><strong>Data Mining &amp; Knowledge Discovery</strong></em
						>.
					</li>
					<li>
						<strong
							>Feuerriegel, Stefan, Saar-Tsechansky, Maytal, &amp; De-Arteaga,
							M.</strong
						>
						(2022). “Algorithmic Fairness in Business Analytics: Directions for Research
						and Practice,”
						<em><strong>Production &amp; Operations Management</strong></em
						>.
					</li>
					<li>
						<strong>De-Arteaga, M., Fogliato, R., &amp; Chouldechova, A.</strong> “A
						case for humans-in-the-loop: decisions in the presence of misestimated
						algorithmic scores.” <em><strong>Extended version of CHI</strong></em
						>.
					</li>
				</ul>
				<h2 id="additional-readings">Additional Readings</h2>
				<ul>
					<li>
						<strong>Henrich, Joseph.</strong> (2020). “The WEIRDest People in the World:
						How the West Became Psychologically Peculiar and Particularly Prosperous.”
						<em><strong>Harvard University Press</strong></em
						>.
					</li>
					<li>
						<strong>Nisbett, Richard E.</strong> (2003). “The Geography of Thought: How
						Asians and Westerners Think Differently…and Why.”
						<em><strong>Free Press</strong></em
						>.
					</li>
				</ul>
				<hr />
				<h4 id="mext-scholarship-research-plan---juan-pablo-gutiérrez-restrepo">
					MEXT Scholarship Research Plan - Juan Pablo Gutiérrez Restrepo
				</h4>
			</div>
		</div>
	</body>
</html>
